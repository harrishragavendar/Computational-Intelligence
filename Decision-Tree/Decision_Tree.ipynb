{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "#   **Decision Tree**\n",
        "---"
      ],
      "metadata": {
        "id": "9uVKC76UglUK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing the Libraries"
      ],
      "metadata": {
        "id": "zn8gob5b7eRK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "spQiuxee5A1y"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculate target count values in each column"
      ],
      "metadata": {
        "id": "wrfQXPnI98hY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_counts(data, column):\n",
        "    counts = data[column].value_counts().to_dict()\n",
        "    return counts"
      ],
      "metadata": {
        "id": "wFEd6tIY7njS"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to calculate Entropy"
      ],
      "metadata": {
        "id": "7pFVTer9-W0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_entropy(counts):\n",
        "    total_count = sum(counts.values())\n",
        "    entropy = 0\n",
        "    for count in counts.values():\n",
        "        probability = count / total_count\n",
        "        entropy -= probability * math.log2(probability)\n",
        "    return round(entropy, 3)"
      ],
      "metadata": {
        "id": "vCT-okQP-rbZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to calculate Information Gain"
      ],
      "metadata": {
        "id": "Dr-S1yGG-vOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_information_gain(data, column, target):\n",
        "    dataset_entropy = calculate_entropy(calculate_counts(data, target))\n",
        "    unique_values = data[column].unique()\n",
        "    weighted_entropies = 0\n",
        "    for value in unique_values:\n",
        "        subset = data[data[column] == value]\n",
        "        subset_entropy = calculate_entropy(calculate_counts(subset, target))\n",
        "        weighted_entropies += (len(subset) / len(data)) * subset_entropy\n",
        "\n",
        "    information_gain = dataset_entropy - weighted_entropies\n",
        "    return round(information_gain, 3)"
      ],
      "metadata": {
        "id": "SNgqY81g-sD9"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculate Entropy and Information Gain of all columns in the dataset"
      ],
      "metadata": {
        "id": "LhbqSo_v7Npb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_all(data, column_names, target):\n",
        "    values = {}\n",
        "    for column in column_names:\n",
        "        print(\"=========================================\")\n",
        "        print(f\"Split: {column}\")\n",
        "        print(f\"{column} Count:\")\n",
        "        counts = calculate_counts(data, column)\n",
        "        column_entropy = 0\n",
        "        for value, count in counts.items():\n",
        "            print(f\"   {value}: {count}\")\n",
        "\n",
        "            subset = data[data[column] == value]\n",
        "            subset_counts = calculate_counts(subset, target)\n",
        "            for key, val in subset_counts.items():\n",
        "                print(f\"      {key}:{subset_counts.get(key)}\")\n",
        "            subset_entropy = calculate_entropy(subset_counts)\n",
        "            print(f\"        Entropy of {column} = {value}: {subset_entropy}\")\n",
        "\n",
        "            column_entropy += (count / len(data)) * subset_entropy\n",
        "\n",
        "        print(f\"Entropy of {column} = {round(column_entropy,3)}\")\n",
        "        info_gain = calculate_information_gain(data, column, target)\n",
        "        print(f\"Information Gain of {column} = {info_gain}\")\n",
        "        values[column] = info_gain\n",
        "        print(\"=========================================\")\n",
        "    root_node = max(values.keys(), key = lambda x:values[x])\n",
        "    print(f\"Root Node of the Decision Tree is: {root_node}\")\n",
        "    print(\"=========================================\")"
      ],
      "metadata": {
        "id": "0Aw4xAj67VXJ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading the Dataset"
      ],
      "metadata": {
        "id": "NM9fkp9wH_vK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('./play_tennis.csv')\n",
        "target = data.columns[-1]\n",
        "column_names = data.columns[1:-1]\n",
        "excluded_columns = ['Day']"
      ],
      "metadata": {
        "id": "4_PwOthdcCgF"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculation of Entropy, Information Gain and finding the Root Node"
      ],
      "metadata": {
        "id": "gGLYk1aAaM4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_all(data, column_names, target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmYmDa54USHV",
        "outputId": "53a28b2a-c59b-4470-aaed-73c2d50628cb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================================\n",
            "Split: Outlook\n",
            "Outlook Count:\n",
            "   Sunny: 5\n",
            "      No:3\n",
            "      Yes:2\n",
            "        Entropy of Outlook = Sunny: 0.971\n",
            "   Rain: 5\n",
            "      Yes:3\n",
            "      No:2\n",
            "        Entropy of Outlook = Rain: 0.971\n",
            "   Overcast: 4\n",
            "      Yes:4\n",
            "        Entropy of Outlook = Overcast: 0.0\n",
            "Entropy of Outlook = 0.694\n",
            "Information Gain of Outlook = 0.246\n",
            "=========================================\n",
            "=========================================\n",
            "Split: Temperature\n",
            "Temperature Count:\n",
            "   Mild: 6\n",
            "      Yes:4\n",
            "      No:2\n",
            "        Entropy of Temperature = Mild: 0.918\n",
            "   Hot: 4\n",
            "      No:2\n",
            "      Yes:2\n",
            "        Entropy of Temperature = Hot: 1.0\n",
            "   Cool: 4\n",
            "      Yes:3\n",
            "      No:1\n",
            "        Entropy of Temperature = Cool: 0.811\n",
            "Entropy of Temperature = 0.911\n",
            "Information Gain of Temperature = 0.029\n",
            "=========================================\n",
            "=========================================\n",
            "Split: Humidity\n",
            "Humidity Count:\n",
            "   High: 7\n",
            "      No:4\n",
            "      Yes:3\n",
            "        Entropy of Humidity = High: 0.985\n",
            "   Normal: 7\n",
            "      Yes:6\n",
            "      No:1\n",
            "        Entropy of Humidity = Normal: 0.592\n",
            "Entropy of Humidity = 0.788\n",
            "Information Gain of Humidity = 0.151\n",
            "=========================================\n",
            "=========================================\n",
            "Split: Wind\n",
            "Wind Count:\n",
            "   Weak: 8\n",
            "      Yes:6\n",
            "      No:2\n",
            "        Entropy of Wind = Weak: 0.811\n",
            "   Strong: 6\n",
            "      No:3\n",
            "      Yes:3\n",
            "        Entropy of Wind = Strong: 1.0\n",
            "Entropy of Wind = 0.892\n",
            "Information Gain of Wind = 0.048\n",
            "=========================================\n",
            "Root Node of the Decision Tree is: Outlook\n",
            "=========================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "GfP-7Jt6Zp0E"
      }
    }
  ]
}